{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad571f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data\"\n",
    "\n",
    "# filename = \"jena_climate_2009_2016_prep_0.csv\"\n",
    "filename = 'jena_climate_2009_2016_simpl.csv'\n",
    "df = pd.read_csv(os.path.join(path, filename), parse_dates=[\"Date Time\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c86ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.tsa import stattools\n",
    "\n",
    "# temps = pd.DataFrame(df['T (degC)'].values, columns=['T (degC)'], index=df['Date Time'])\n",
    "\n",
    "# acf_djia, confint_djia, qstat_djia, pvalues_djia = stattools.acf(temps,\n",
    "#                                                              adjusted=True,\n",
    "#                                                              nlags=96,\n",
    "#                                                              qstat=True,\n",
    "#                                                              fft=True,\n",
    "#                                                              alpha = 0.05, )\n",
    "\n",
    "# plt.figure(figsize=(7, 5))\n",
    "# plt.plot(pd.Series(acf_djia), color='r', linewidth=2)\n",
    "# plt.title('Autocorrelation plot', weight='bold', fontsize=16)\n",
    "# plt.xlabel('Lag', weight='bold', fontsize=14)\n",
    "# plt.ylabel('Value', weight='bold', fontsize=14)\n",
    "# plt.xticks(weight='bold', fontsize=12, rotation=45)\n",
    "# plt.yticks(weight='bold', fontsize=12)\n",
    "# plt.grid(color = 'y', linewidth = 0.5)\n",
    "\n",
    "########################################################################################################################\n",
    "# There must be a way to optimize the number of lags as a model param:\n",
    "# It probably needs to redefine each regression function, so it becomes a model param to be optimized.\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bdcca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Dataprep utils\n",
    "##################\n",
    "\n",
    "def date_to_timestamp(df, date_col = \"Date Time\"):\n",
    "    \"\"\"\n",
    "    Transform dates to datetime, then timestamp in sec\n",
    "    \"\"\"\n",
    "    date_time = df[date_col]\n",
    "    if not is_datetime(date_time):\n",
    "        date_time = pd.to_datetime(df[date_col])\n",
    "    return date_time.map(pd.Timestamp.timestamp)\n",
    "\n",
    "def timestamp_to_daily_sin_cos(timestamp_s):\n",
    "    day = 24*60*60\n",
    "    return np.sin(timestamp_s * (2 * np.pi / day)), np.cos(timestamp_s * (2 * np.pi / day))\n",
    "\n",
    "def timestamp_to_weekly_sin_cos(timestamp_s):\n",
    "    day = 24*60*60\n",
    "    week = day*7\n",
    "    return np.sin(timestamp_s * (2 * np.pi / week)), np.cos(timestamp_s * (2 * np.pi / week))\n",
    "\n",
    "def timestamp_to_monthly_sin_cos(timestamp_s):\n",
    "    day = 24*60*60\n",
    "    month = day*30\n",
    "    return np.sin(timestamp_s * (2 * np.pi / month)), np.cos(timestamp_s * (2 * np.pi / month))\n",
    "\n",
    "def timestamp_to_yearly_sin_cos(timestamp_s):\n",
    "    day = 24*60*60\n",
    "    year = (365.2425)*day\n",
    "    return np.sin(timestamp_s * (2 * np.pi / year)), np.cos(timestamp_s * (2 * np.pi / year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c48263",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_s = date_to_timestamp(df, \"Date Time\")\n",
    "df['Day sin'], df['Day cos'] = timestamp_to_daily_sin_cos(timestamp_s)\n",
    "df['Year sin'], df['Year cos'] = timestamp_to_yearly_sin_cos(timestamp_s)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea168b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeries():\n",
    "    def __init__(self, df, y, date_col=\"Date Time\", lags=16, test_len=24):\n",
    "        self.date_time = df[date_col] if is_datetime(df[date_col]) else pd.to_datetime(df[date_col])\n",
    "        self.y = df[y]\n",
    "        self.X = df.drop(columns=[y, date_col])\n",
    "        self.lags = lags\n",
    "        self.test_len = test_len\n",
    "        \n",
    "        self._add_lags()\n",
    "        self._train_test_split()\n",
    "        \n",
    "    def _add_lags(self):\n",
    "        if self.lags < 1:\n",
    "            return\n",
    "        for i in range(1, self.lags + 1, 1):\n",
    "            self.X[f\"lag_{i}\"] = [np.nan]*i + list(self.y[:-i])\n",
    "\n",
    "        idx = ~self.X[f\"lag_{self.lags}\"].isna()\n",
    "        self.date_time = self.date_time[idx]\n",
    "        self.X = self.X[idx]\n",
    "        self.y = self.y[idx]\n",
    "        \n",
    "    def _train_test_split(self):\n",
    "        self.Xtrain = self.X.iloc[:-self.test_len,:]\n",
    "        self.ytrain = self.y[:-self.test_len]\n",
    "        self.Xtest = self.X.iloc[-self.test_len:,:]\n",
    "        self.ytest = self.y[-self.test_len:]\n",
    "\n",
    "    def get_Xtrain(self):\n",
    "        return self.Xtrain\n",
    "\n",
    "    def get_Xtest(self):\n",
    "        return self.Xtest\n",
    "\n",
    "    def get_ytrain(self):\n",
    "        return self.ytrain\n",
    "    \n",
    "    def get_ytest(self):\n",
    "        return self.ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d81864",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TimeSeries(df, y='T (degC)', lags=72)\n",
    "len(ts.get_Xtrain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1057411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ts.get_ytrain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"LR\": {},\n",
    "    \"XGB\": {\n",
    "        'learning_rate': 0.05,\n",
    "        'n_estimators': 500\n",
    "        },\n",
    "    \"Ridge_\": {\n",
    "        'alpha': 0.2,\n",
    "        'positive': True,\n",
    "        'solver': 'lbfgs'\n",
    "        },\n",
    "    \"Lasso_\": {\n",
    "        'alpha': 0.1,\n",
    "        'warm_start': True,\n",
    "        'positive': True,\n",
    "        'selection': 'cyclic'\n",
    "        },\n",
    "    \"Elasticnet_\": {\n",
    "        'alpha': 0.75,\n",
    "        'l1_ratio': 0.25,\n",
    "        'warm_start': True,\n",
    "        'positive': True,\n",
    "        'selection': 'cyclic'\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60763f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Packages:\n",
    "import functools\n",
    "import optuna\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor as XGBReg\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "############################################\n",
    "# Decorator:\n",
    "def optimizer(model):\n",
    "    def deco_optim(parameterizer):\n",
    "        @functools.wraps(parameterizer)\n",
    "        def wrapper_optim(*args):\n",
    "            params = parameterizer(*args)\n",
    "            return model(**params)\n",
    "        return wrapper_optim\n",
    "    return deco_optim\n",
    "\n",
    "\n",
    "############################################\n",
    "# Set trial parameters for each model:\n",
    "@optimizer(LinearRegression)\n",
    "def LinearRegression_optimizer(trial):\n",
    "    params = {}\n",
    "    return params\n",
    "\n",
    "@optimizer(Ridge)\n",
    "def Ridge_optimizer(trial):\n",
    "    params = {\n",
    "        \"alpha\": trial.suggest_float(\"ridge_alpha\", 0.1, 2),\n",
    "        \"positive\": trial.suggest_categorical(\"ridge_positive\", [True, False]),\n",
    "        \"solver\": \"auto\"\n",
    "        }\n",
    "    return params\n",
    "\n",
    "@optimizer(Lasso)\n",
    "def Lasso_optimizer(trial):\n",
    "    params = {\n",
    "        \"alpha\": trial.suggest_float(\"lasso_alpha\", 0.1, 2),\n",
    "        'warm_start': trial.suggest_categorical(\"lasso_warm_start\", [True, False]),\n",
    "        \"positive\": trial.suggest_categorical(\"lasso_positive\", [True, False]),\n",
    "        \"selection\": trial.suggest_categorical(\"lasso_selection\", [\"cyclic\", \"random\"])\n",
    "        }\n",
    "    return params\n",
    "\n",
    "@optimizer(ElasticNet)\n",
    "def ElasticNet_optimizer(trial):\n",
    "    params = {\n",
    "        \"alpha\": trial.suggest_float(\"elastic_alpha\", 0.1, 2),\n",
    "        \"l1_ratio\": trial.suggest_float(\"elastic_l1_ratio\", 0.1, 1),\n",
    "        'warm_start': trial.suggest_categorical(\"elastic_warm_start\", [True, False]),\n",
    "        \"positive\": trial.suggest_categorical(\"elastic_positive\", [True, False]),\n",
    "        \"selection\": trial.suggest_categorical(\"elastic_selection\", [\"cyclic\", \"random\"])\n",
    "        }\n",
    "    return params\n",
    "\n",
    "@optimizer(XGBReg)\n",
    "def XGBReg_optimizer(trial):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"xgbr_learning_rate\", 0.1, 1),\n",
    "        \"n_estimators\": trial.suggest_int(\"xgbr_n_estimators\", 200, 500, 100),\n",
    "        'max_depth': trial.suggest_int(\"xgbr_max_depth\", 3, 5, 1),\n",
    "        \"loss\": \"squared_error\" # trial.suggest_categorical(\"xgbr_loss\", [\"squared_error\", \"absolute_error\", \"quantile\"])\n",
    "        }\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3980c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, Xtrain, ytrain, model_list):\n",
    "\n",
    "    # Setup values for the hyperparameters optimization:\n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", model_list)\n",
    "    classifier_optimizer = f\"{classifier_name}_optimizer\"\n",
    "    classifier_obj = eval(classifier_optimizer)(trial)\n",
    "\n",
    "    # Scoring method:\n",
    "    score = model_selection.cross_val_score(\n",
    "        classifier_obj,\n",
    "        Xtrain, ytrain,\n",
    "        n_jobs=-1,\n",
    "        cv=5,\n",
    "        error_score=float(np.inf)\n",
    "    )\n",
    "\n",
    "    # Return accuracy\n",
    "    return score.mean()\n",
    "\n",
    "\n",
    "def optimize(self, model_list, n_trials=5):\n",
    "    \"\"\"\n",
    "    Run optimizer\n",
    "    note: to pass args to the objective func, wrap it inside a lambda func + args\n",
    "    and call the lambda func in study.optimize()\n",
    "    \"\"\"\n",
    "    \n",
    "    Xtrain = self.get_Xtrain()\n",
    "    ytrain = self.get_ytrain()\n",
    "    \n",
    "    objective_func = lambda trial: objective(trial, Xtrain, ytrain, model_list)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_func, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    self.study = study\n",
    "\n",
    "TimeSeries.optimize = optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_list=[\"LinearRegression\", \"Ridge\", \"Lasso\", \"ElasticNet\", \"XGBReg\"]\n",
    "model_list=[\"LinearRegression\", \"XGBReg\"]\n",
    "ts.optimize(model_list=model_list, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(self):\n",
    "\n",
    "    def clean_param_names(params):\n",
    "        \"\"\"\n",
    "        Retrieve the original param names,\n",
    "        so they can be passed to the best model\n",
    "        \"\"\"\n",
    "        clean = lambda p: \"_\".join(p.split(\"_\")[1:])\n",
    "        return {clean(p): v for p, v in params.items()}\n",
    "\n",
    "    study = self.study\n",
    "    best_value = study.best_value\n",
    "    best_params = study.best_params\n",
    "    best_model = best_params.pop('classifier')\n",
    "    best_params = clean_param_names(best_params)\n",
    "\n",
    "    ############################################\n",
    "    # Getting the best result\n",
    "    print(f\"\\nBest accuracy: {best_value}\")\n",
    "    print(f\"Best algorithm: {best_model}\")\n",
    "    print(f\"Best parameters (ready to use): {best_params}\\n\")\n",
    "\n",
    "    return best_model, best_params\n",
    "\n",
    "def performance(model):\n",
    "    pass\n",
    "\n",
    "def train_best_model(self):\n",
    "\n",
    "    best_model, best_params = self.get_best_model()\n",
    "\n",
    "    print(f\"Running {best_model} as best best\")\n",
    "    print(\"Params:\")\n",
    "    print(best_params)\n",
    "\n",
    "    model = eval(best_model)(**best_params)\n",
    "    Xtrain = np.array(self.get_Xtrain())\n",
    "    ytrain = np.array(self.get_ytrain()).reshape(-1, 1)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "\n",
    "    self.model = model\n",
    "\n",
    "def predict(self, what=\"train\"):\n",
    "    model = self.model\n",
    "    if what == \"train\":\n",
    "        return model.predict(np.array(self.get_Xtrain()))\n",
    "    elif what == \"test\":\n",
    "        return model.predict(np.array(self.get_Xtest()))\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "TimeSeries.get_best_model = get_best_model\n",
    "TimeSeries.train_best_model = train_best_model\n",
    "TimeSeries.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8936328",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.train_best_model()\n",
    "# train_pred, test_pred = ts.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0dc46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(self):\n",
    "    ytrain = self.get_ytrain().tolist()\n",
    "    ytest = self.get_ytest().tolist()\n",
    "    test_pred = self.predict(\"test\")\n",
    "    date_time = self.date_time\n",
    "    \n",
    "    plt.figure(figsize=(18, 8))\n",
    "\n",
    "    plt.plot(date_time[-self.test_len:], ytest, linewidth=2, label=\"Observed\")\n",
    "    plt.plot(date_time[-self.test_len:], test_pred, linewidth=2, c='orange', label=\"predicted\")\n",
    "\n",
    "    plt.xlabel('Time', fontsize=18)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.ylabel('Values', fontsize=18)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "TimeSeries.plot = plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0405a15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 (timeSeries)",
   "language": "python",
   "name": "timeseries"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
